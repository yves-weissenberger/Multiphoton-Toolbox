{
    "docs": [
        {
            "location": "/", 
            "text": "twoptb - Two photon tool-box\n\n\nThis is a toolbox for the analysis of two-photon imaging data. It is optimised for the analysis of two-photon calcium imaging data. \n\n\nThe toolbox is centred around efficient data handling via linking of data to hdf5 files. This enables access to diverse aspects of the data and underlies in large part the extensibility of the toolbox. \n\n\nThe main strength of this toolbox, as compared to the many that already exist, are several powerful tools for data visualisation.\n\n\nA link to the repository may be found \n here", 
            "title": "Home"
        }, 
        {
            "location": "/#twoptb-two-photon-tool-box", 
            "text": "This is a toolbox for the analysis of two-photon imaging data. It is optimised for the analysis of two-photon calcium imaging data.   The toolbox is centred around efficient data handling via linking of data to hdf5 files. This enables access to diverse aspects of the data and underlies in large part the extensibility of the toolbox.   The main strength of this toolbox, as compared to the many that already exist, are several powerful tools for data visualisation.  A link to the repository may be found   here", 
            "title": "twoptb - Two photon tool-box"
        }, 
        {
            "location": "/install/", 
            "text": "Installation\n\n\nThe package has many dependencies so by far the easiest way to install the package is to download \n Anaconda 2.7\n. Thereafter only two additional packages need to be installed. These are:\n\n\n tifffile \n\n\n\n pyqtgraph \n\n\n\nFor windows the former is easily installed from \n here \n, the latter from \n here \n.\n\n\nThereafter simply download the repository from \n here \n and install it by running\n\n\npip install .\n\n\n\nin the first twoptb directory (i.e. the one containing setup.py).\n\n\nWindows\n\n\nThe package has many dependencies so by far the easiest way to install the package is to download Anaconda 2.7. Thereafter only two additional packages need to be installed. These are:\n\n\ntifffile\npyqtgraph\nFor windows the former is easily installed from here , the latter from here .\n\n\nThereafter simply download the repository and install it by running\n\n\npip install . \nin the first twoptb directory (i.e. the one containing setup.py).", 
            "title": "Installation"
        }, 
        {
            "location": "/install/#installation", 
            "text": "The package has many dependencies so by far the easiest way to install the package is to download   Anaconda 2.7 . Thereafter only two additional packages need to be installed. These are:   tifffile    pyqtgraph   For windows the former is easily installed from   here  , the latter from   here  .  Thereafter simply download the repository from   here   and install it by running  pip install .  in the first twoptb directory (i.e. the one containing setup.py).", 
            "title": "Installation"
        }, 
        {
            "location": "/install/#windows", 
            "text": "The package has many dependencies so by far the easiest way to install the package is to download Anaconda 2.7. Thereafter only two additional packages need to be installed. These are:  tifffile\npyqtgraph\nFor windows the former is easily installed from here , the latter from here .  Thereafter simply download the repository and install it by running  pip install . \nin the first twoptb directory (i.e. the one containing setup.py).", 
            "title": "Windows"
        }, 
        {
            "location": "/overview/", 
            "text": "Overview\n\n\nThis page is intended to provide a quick overview of the workflow. For more information please see the \nUser Guide\n\n\nTypical Set of function calls to preprocess data\n\n\nMost important functions have (will soon have) help. To view the help run the function simply as:\n\n\nFirst format data by calling \n\n\npython /path/to/twoptb/twoptb/scripts/convert_to_hdf5.py\n\n\n\nNext motion register data\n\n\npython /path/to/twoptb/twoptb/scripts/motion_register_data.py\n\n\n\nThen draw ROIs either manually\n\n\npython /path/to/twoptb/twoptb/ROIs/ROI_Drawer.py\n\n\n\nor automatically\n\n\n/path/to/twoptb/twoptb/ROIs/run_roi_finder.py\n\n\n\nfollowed by manul curation using the \"ROI_Drawer\"\n\n\nThen, if the data contains several separate acquisition runs involving the same cells\n\n\n/path/to/twoptb/twoptb/ROIs/share_roiinfo.py\n\n\n\nFinally extract traces from the cells:\n\n\n/path/to/twoptb/twoptb/ROIs/extract_roi_traces.py\n\n\n\nGeneral Advice\n\n\nIf you know how to, I would strongly recommend adding the twoptb scripts and ROI paths to you python path as it will make calling scripts much quicker.\n\n\nThe main purpose of this toolbox is two-photon imaging data preprocessing. The key functions defining the pipeline are run by calling (via command line)\n\n\npython /path/to/twoptb/twoptb/scripts/generic_script.py -h", 
            "title": "Quickstart"
        }, 
        {
            "location": "/overview/#overview", 
            "text": "This page is intended to provide a quick overview of the workflow. For more information please see the  User Guide", 
            "title": "Overview"
        }, 
        {
            "location": "/overview/#typical-set-of-function-calls-to-preprocess-data", 
            "text": "Most important functions have (will soon have) help. To view the help run the function simply as:  First format data by calling   python /path/to/twoptb/twoptb/scripts/convert_to_hdf5.py  Next motion register data  python /path/to/twoptb/twoptb/scripts/motion_register_data.py  Then draw ROIs either manually  python /path/to/twoptb/twoptb/ROIs/ROI_Drawer.py  or automatically  /path/to/twoptb/twoptb/ROIs/run_roi_finder.py  followed by manul curation using the \"ROI_Drawer\"  Then, if the data contains several separate acquisition runs involving the same cells  /path/to/twoptb/twoptb/ROIs/share_roiinfo.py  Finally extract traces from the cells:  /path/to/twoptb/twoptb/ROIs/extract_roi_traces.py", 
            "title": "Typical Set of function calls to preprocess data"
        }, 
        {
            "location": "/overview/#general-advice", 
            "text": "If you know how to, I would strongly recommend adding the twoptb scripts and ROI paths to you python path as it will make calling scripts much quicker.  The main purpose of this toolbox is two-photon imaging data preprocessing. The key functions defining the pipeline are run by calling (via command line)  python /path/to/twoptb/twoptb/scripts/generic_script.py -h", 
            "title": "General Advice"
        }, 
        {
            "location": "/user_guide/data_conversion/", 
            "text": "Data conversion\n\n\nPrior to any preprocessing or analysis of the raw data, it is converted from the raw data format, (i.e. .tif) to HDF5 for convenience. The resulting HDF file serves as a central access point for the multimodal (i.e. two-photon imaging data, video-data, stimulus files etc.).  \n\n\nData is converted to HDF5 by running, in terminal \n\n\npython /path/to/twoptb/twoptb/scripts/convert_to_hdf5.py /path/to/data_folder/\n\n\n\nIn order to preprocess data properly, the script requires a certain directory and file structure.  Firstly, it assumes that imaging data are stored in the form of .tif files with the metadata required for reading them. Additionally, it assumes that these .tif files are stored in directories containing GRABinfo files (which contain image acquisition parameters) and optionally stimulus script files (outDat.mat file in the example, see below for further details). Finally, it assumes that data are in a certain directory structure: \n\n\nExpects certain folder structure e.g.\n/home\n/AIAK_2\n    /29082017\n        /session01\n            /Acq1.tif\n            GRABinfo.mat\n            outDat.mat\n            ...\n\n        /session02\n            /Acq1.tif\n            GRABinfo.mat\n            outDat.mat\n            ...\n\n        /session03\n            /Acq1.tif\n            GRABinfo.mat\n            outDat.mat\n            ...\n\n\n\nIn the case of the above directory structure, the script above would be run as\n\n\npython /path/to/twoptb/twoptb/scripts/convert_to_hdf5.py /home/AIAK_2/\n\n\n\nand would create a single HDF5 file with data from all acquired sessions. Importantly, to optimally use this toolbox, all sessions in the example above should either be acquisitions of the same group of cells, or should all be acquisitions of different groups of cells. \nRunning this command would create a single HDF5 file from which raw-data, acquisition parameters and stimulus data could be convienetly and reproducibly accessed. \n\n\nLinking stimulus scripts\n\n\nA core feature of the toolbox is the centrality of the hdf5 file as a link for the multimodal data. For the analysis of most imaging datasets, additional information is required. This can be of the form of behavioural timestamps, simultaneously recorded video (currently not supported), or stimulus timestamps. Integrating this timestamped data with the HDF5 file requires processing of the raw form of the timestamp data. In order to link custom scripts to the HDF5 file, a readout script must be added to the \"load_events.py\" file which can be found in \n\n\ntwoptb/twoptb/file_management/load_events.py\n\n\n\nAfter adding the appropriate function, the data must be directed to this function by adding the appropriate path to\n\n\ntwoptb/twoptb/file_management/load_images.py\n\n\n\nFor example, to extract data from the ouDat.mat file in the example directory structure above \"load_images.py\" contains the following elif statement \n\n\n    elif 'outDat' in fname:\n        if '._' not in fname:\n            matFilePth = os.path.join(directory,fname)\n            print matFilePth\n            stimattrs = get_triggers(matFilePth)\n\n\n\nwhich directs processing of the outDat file to the function \"get_triggers\" which can be found in load_events.py.\n\n\nOutput Folder Structure\n\n\nRunning the above script should give rise to the above directory structure\n    /home\n    /AIAK_2\n        /29082017\n            /...\n        /processed\n            /29082017_AIAK_2\n                29082017_AIAK_2.h5\n                /GRABinfos\n                /stims\n                /regInfo\n                /ROIs\n\n\n    proc_log.txt\n\n\n\nAfter this initial preprocessing step next is \nmotion registration", 
            "title": "Data Conversion"
        }, 
        {
            "location": "/user_guide/data_conversion/#data-conversion", 
            "text": "Prior to any preprocessing or analysis of the raw data, it is converted from the raw data format, (i.e. .tif) to HDF5 for convenience. The resulting HDF file serves as a central access point for the multimodal (i.e. two-photon imaging data, video-data, stimulus files etc.).    Data is converted to HDF5 by running, in terminal   python /path/to/twoptb/twoptb/scripts/convert_to_hdf5.py /path/to/data_folder/  In order to preprocess data properly, the script requires a certain directory and file structure.  Firstly, it assumes that imaging data are stored in the form of .tif files with the metadata required for reading them. Additionally, it assumes that these .tif files are stored in directories containing GRABinfo files (which contain image acquisition parameters) and optionally stimulus script files (outDat.mat file in the example, see below for further details). Finally, it assumes that data are in a certain directory structure:   Expects certain folder structure e.g.\n/home\n/AIAK_2\n    /29082017\n        /session01\n            /Acq1.tif\n            GRABinfo.mat\n            outDat.mat\n            ...\n\n        /session02\n            /Acq1.tif\n            GRABinfo.mat\n            outDat.mat\n            ...\n\n        /session03\n            /Acq1.tif\n            GRABinfo.mat\n            outDat.mat\n            ...  In the case of the above directory structure, the script above would be run as  python /path/to/twoptb/twoptb/scripts/convert_to_hdf5.py /home/AIAK_2/  and would create a single HDF5 file with data from all acquired sessions. Importantly, to optimally use this toolbox, all sessions in the example above should either be acquisitions of the same group of cells, or should all be acquisitions of different groups of cells. \nRunning this command would create a single HDF5 file from which raw-data, acquisition parameters and stimulus data could be convienetly and reproducibly accessed.", 
            "title": "Data conversion"
        }, 
        {
            "location": "/user_guide/data_conversion/#linking-stimulus-scripts", 
            "text": "A core feature of the toolbox is the centrality of the hdf5 file as a link for the multimodal data. For the analysis of most imaging datasets, additional information is required. This can be of the form of behavioural timestamps, simultaneously recorded video (currently not supported), or stimulus timestamps. Integrating this timestamped data with the HDF5 file requires processing of the raw form of the timestamp data. In order to link custom scripts to the HDF5 file, a readout script must be added to the \"load_events.py\" file which can be found in   twoptb/twoptb/file_management/load_events.py  After adding the appropriate function, the data must be directed to this function by adding the appropriate path to  twoptb/twoptb/file_management/load_images.py  For example, to extract data from the ouDat.mat file in the example directory structure above \"load_images.py\" contains the following elif statement       elif 'outDat' in fname:\n        if '._' not in fname:\n            matFilePth = os.path.join(directory,fname)\n            print matFilePth\n            stimattrs = get_triggers(matFilePth)  which directs processing of the outDat file to the function \"get_triggers\" which can be found in load_events.py.", 
            "title": "Linking stimulus scripts"
        }, 
        {
            "location": "/user_guide/data_conversion/#output-folder-structure", 
            "text": "Running the above script should give rise to the above directory structure\n    /home\n    /AIAK_2\n        /29082017\n            /...\n        /processed\n            /29082017_AIAK_2\n                29082017_AIAK_2.h5\n                /GRABinfos\n                /stims\n                /regInfo\n                /ROIs      proc_log.txt  After this initial preprocessing step next is  motion registration", 
            "title": "Output Folder Structure"
        }, 
        {
            "location": "/user_guide/motionreg/", 
            "text": "Motion registration\n\n\nTo run motion registration on a dataset that has been converted to hdf5, simply run\n\n\n/path/to/twoptb/scripts/motion_register_data.py path/to/hdf_file.h5\n\n\n\nMotion Registration Algorithm\n\n\nMotion registration is implemented using the efficient subpixel registration algorithm provided by Guizmar. \n\n\nMean image selection\n\n\nMean images are computed by", 
            "title": "Motion Registration"
        }, 
        {
            "location": "/user_guide/motionreg/#motion-registration", 
            "text": "To run motion registration on a dataset that has been converted to hdf5, simply run  /path/to/twoptb/scripts/motion_register_data.py path/to/hdf_file.h5", 
            "title": "Motion registration"
        }, 
        {
            "location": "/user_guide/motionreg/#motion-registration-algorithm", 
            "text": "Motion registration is implemented using the efficient subpixel registration algorithm provided by Guizmar.", 
            "title": "Motion Registration Algorithm"
        }, 
        {
            "location": "/user_guide/motionreg/#mean-image-selection", 
            "text": "Mean images are computed by", 
            "title": "Mean image selection"
        }, 
        {
            "location": "/user_guide/rois/", 
            "text": "ROI Definition Methods\n\n\nAutomatic approach\n\n\nTraining an ROI classifer\n\n\nUsing a pre-trained ROI classifier\n\n\nWe have developed a simple algorithm for automatic roi definition. To run this algorithm, run:\n\n\npython /path/to/twoptb/twoptb/ROIs/run_roi_finder.py -sess -1 -ded 3 2 2 -thresh 0.96 /path/to/hdf5.h5 /path/to/twoptb/twoptb/classifiers/zoom1_GTMK.p\n\n\n\n\n\nManual curation\n\n\nImage of the GUI used for ROI and data curation", 
            "title": "ROI Definition"
        }, 
        {
            "location": "/user_guide/rois/#roi-definition-methods", 
            "text": "", 
            "title": "ROI Definition Methods"
        }, 
        {
            "location": "/user_guide/rois/#automatic-approach", 
            "text": "", 
            "title": "Automatic approach"
        }, 
        {
            "location": "/user_guide/rois/#training-an-roi-classifer", 
            "text": "", 
            "title": "Training an ROI classifer"
        }, 
        {
            "location": "/user_guide/rois/#using-a-pre-trained-roi-classifier", 
            "text": "We have developed a simple algorithm for automatic roi definition. To run this algorithm, run:  python /path/to/twoptb/twoptb/ROIs/run_roi_finder.py -sess -1 -ded 3 2 2 -thresh 0.96 /path/to/hdf5.h5 /path/to/twoptb/twoptb/classifiers/zoom1_GTMK.p", 
            "title": "Using a pre-trained ROI classifier"
        }, 
        {
            "location": "/user_guide/rois/#manual-curation", 
            "text": "", 
            "title": "Manual curation"
        }, 
        {
            "location": "/user_guide/rois/#image-of-the-gui-used-for-roi-and-data-curation", 
            "text": "", 
            "title": "Image of the GUI used for ROI and data curation"
        }, 
        {
            "location": "/user_guide/trace_extraction/", 
            "text": "", 
            "title": "Trace Extraction"
        }, 
        {
            "location": "/user_guide/across_days/", 
            "text": "Matching ROIs across days\n\n\nIf the same group of cells is repeatedly imaged across days, many experiments require matching cells across days. To enable this, \n\n\nAlgorithmic Approach\n\n\nGUI for curation", 
            "title": "Across Day Analysis"
        }, 
        {
            "location": "/user_guide/across_days/#matching-rois-across-days", 
            "text": "If the same group of cells is repeatedly imaged across days, many experiments require matching cells across days. To enable this,", 
            "title": "Matching ROIs across days"
        }, 
        {
            "location": "/user_guide/across_days/#algorithmic-approach", 
            "text": "", 
            "title": "Algorithmic Approach"
        }, 
        {
            "location": "/user_guide/across_days/#gui-for-curation", 
            "text": "", 
            "title": "GUI for curation"
        }
    ]
}